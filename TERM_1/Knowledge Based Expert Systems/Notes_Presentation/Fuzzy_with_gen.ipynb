{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Fuzzy with gen.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "lWI-K3Xrg7IH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        },
        "outputId": "5f8f869a-0d2e-4f0c-fe57-02f2dd1872e6"
      },
      "source": [
        "\n",
        "import random\n",
        "import numpy as np\n",
        "from copy import deepcopy\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "class EVOLUTIONARY_ANFIS:\n",
        "  def __init__(self,functions,generations,offsprings,mutationRate,learningRate,chance,ruleComb):\n",
        "    self.functions = functions\n",
        "    self.generations = generations\n",
        "    self.offsprings = offsprings\n",
        "    self.mutationRate = mutationRate\n",
        "    self.learningRate = learningRate\n",
        "    self.chance = chance #50 percent chance of changing std.\n",
        "    self.ruleComb = ruleComb\n",
        "    self._noParam = 2\n",
        "\n",
        "  def gaussian(self,x, mu, sig):\n",
        "    return np.exp((-np.power(x - mu, 2.) / (2 * np.power(sig, 2.))))\n",
        "    \n",
        "  def initialize(self,X):\n",
        "    functions = self.functions\n",
        "    noParam = self._noParam\n",
        "    ruleComb = self.ruleComb\n",
        "    inputs = np.zeros((X.shape[1],X.shape[0],functions))\n",
        "    Ant = np.zeros((noParam,X.shape[1],X.shape[0],functions))\n",
        "    L1 = np.zeros((X.shape[1],X.shape[0],functions))\n",
        "    if ruleComb == \"simple\":\n",
        "      L2 = np.zeros((X.shape[0],functions)) \n",
        "    elif ruleComb == \"complete\":\n",
        "      rules = X.shape[1]**functions\n",
        "      L2 = np.zeros((X.shape[0],rules))   \n",
        "    return inputs, Ant, L1, L2\n",
        "    \n",
        "  def mutation(self,arr):\n",
        "     mutationRate = self.mutationRate\n",
        "     learningRate = self.learningRate\n",
        "     chance = self.chance\n",
        "     temp = np.asarray(arr)   # Cast to numpy array\n",
        "     mean = temp[0]\n",
        "     meanShape = mean.shape\n",
        "     std = temp[1]\n",
        "     stdShape = std.shape\n",
        "     mean = mean.flatten()    # Flatten to 1D\n",
        "     std = std.flatten()    # Flatten to 1D\n",
        "     num = int(mutationRate*mean.size) # number of elements to get\n",
        "     if random.uniform(0,1)>chance:\n",
        "         inds = np.random.choice(mean.size, size=num)   # Get random indices\n",
        "         mean[inds] -= np.random.uniform(0,1,size=num)*learningRate        # Fill with something\n",
        "         mean = mean.reshape(meanShape)                     # Restore original shape\n",
        "         std = std.reshape(stdShape)\n",
        "     else:\n",
        "      inds = np.random.choice(std.size, size=num)   # Get random indices\n",
        "      std[inds] -= np.random.uniform(0,1,size=num)*learningRate        # Fill with something\n",
        "      std = std.reshape(stdShape)                     # Restore original shape    \n",
        "      std = np.where(std==0, 0.0001, std) #standard deviation cannot be zero\n",
        "      #temp = np.where(temp<=0, 0.0001, temp)\n",
        "      #temp = np.where(temp>=1, 0.9999, temp)\n",
        "           \n",
        "      mean = mean.reshape(meanShape)\n",
        "    #temp[0] = mean\n",
        "    #temp[1] = std\n",
        "    #return temp   \n",
        "        \n",
        "        \n",
        "  def init_population(self,X):\n",
        "    noParam = self._noParam\n",
        "    functions = self.functions\n",
        "    offsprings = self.offsprings\n",
        "    bestParam = np.random.rand(noParam,X.shape[1],functions)\n",
        "    parentParam = deepcopy(bestParam)\n",
        "    popParam = []\n",
        "    for i in range(offsprings):\n",
        "      popParam.append(self.mutation(parentParam))\n",
        "    return popParam\n",
        "    \n",
        "  def init_model(self,model=LinearRegression()):\n",
        "    models = []\n",
        "    for i in range(self.functions):\n",
        "      models.append(model)\n",
        "    return models\n",
        "\n",
        "  def forwardPass(self,param,X,inputs,Ant,L1,L2,functions):\n",
        "    noParam = self._noParam\n",
        "        \n",
        "    for i in range(X.shape[1]):   #input variables     \n",
        "      inputs[i] = np.repeat(X[:,i].reshape(-1,1),functions,axis=1)\n",
        "\n",
        "    for ii in range(noParam):   #Anticedent parameters\n",
        "       for i in range(X.shape[1]):\n",
        "          Ant[ii] = np.repeat(param[ii][i,:].reshape(1,-1),X.shape[0],axis=0)\n",
        "        \n",
        "    for i in range(X.shape[1]):  #Membership values using Gaussian membership function      \n",
        "     L1[i,:,:] = self.gaussian(x=inputs[i],mu=Ant[0][i],sig=Ant[1][i])\n",
        "      \n",
        "    for j in range(functions):      #rule\n",
        "      for i in range(1,X.shape[1]):\n",
        "        L2[:,j] = (L1[i-1,:,j]*L1[i,:,j])#+(L1[i-1,:,j]+L1[i,:,j])\n",
        "    \n",
        "    summ = np.sum(L2,axis=1).reshape(-1,1) #Weights normalization\n",
        "    summation = np.repeat(summ,functions,axis=1)\n",
        "    L3 = L2/summation\n",
        "    L3 = np.round(L3,5)\n",
        "    #Errorcheck = np.sum(L3,axis=1)\n",
        "    \n",
        "    consequent = X\n",
        "    L4 = np.zeros((functions,X.shape[0],X.shape[1]))\n",
        "    for i in range (functions):\n",
        "      L4[i] = consequent\n",
        "      L4[i] = L4[i]*L3[:,i].reshape(-1,1)\n",
        "    return L1,L2,L3,L4\n",
        "    \n",
        "  def linear_fit(self,L3,L4,X,y,functions,models):\n",
        "    pred_train = np.zeros((X.shape[0],functions))\n",
        "    for i in range(functions):\n",
        "      models[i].fit(L4[i],y)\n",
        "      predTemp = models[i].predict(L4[i])\n",
        "      pred_train[:,i] = predTemp[:,0]       \n",
        "    pred_train = pred_train*L3 #consequent function output * normalized weights\n",
        "    pred_train = np.sum(pred_train,axis=1)\n",
        "    return pred_train, models \n",
        "\n",
        "  def linear_predict(self,L3,L4,X,functions,Trained_models):\n",
        "    pred_test = np.zeros((X.shape[0],functions))\n",
        "    for i in range(functions):            \n",
        "      predTemp = Trained_models[i].predict(L4[i]).reshape(-1,1)               \n",
        "      pred_test[:,i] = predTemp[:,0]\n",
        "    pred_test = pred_test*L3 #consequent function output * normalized weights\n",
        "    pred_test = np.sum(pred_test,axis=1)\n",
        "    return pred_test\n",
        "\n",
        "    @staticmethod\n",
        "  def rmse(true, pred):\n",
        "    loss = np.sqrt(np.mean((true - pred)**2))\n",
        "    return loss\n",
        "\n",
        "  def fit(self,X_train,y_train,X_test=None,y_test=None,optimize_test_data=False):\n",
        "    generations = self.generations\n",
        "    offsprings = self.offsprings\n",
        "    functions = self.functions\n",
        "    popParam = self.init_population(X_train)\n",
        "    inputsTrain,AntTrain,L1Train,L2Train = self.initialize(X_train)\n",
        "    if optimize_test_data:\n",
        "      inputsTest,AntTest,L1Test,L2Test = self.initialize(X_test)\n",
        "    models = self.init_model()\n",
        "    bestParam = popParam[0]\n",
        "    for gen in range(generations):\n",
        "      parentParam = deepcopy(bestParam)\n",
        "      popParam[0] = deepcopy(bestParam)\n",
        "      for ii in range(1,offsprings):\n",
        "        mut = self.mutation(parentParam)        \n",
        "        popParam[ii] = deepcopy(mut)\n",
        "                    \n",
        "      PopulationError = []\n",
        "      bestModelLst = []\n",
        "      for i in range(len(popParam)):\n",
        "        L1,L2,L3,L4 = self.forwardPass(popParam[i],X_train,inputsTrain,AntTrain,L1Train,L2Train,functions)\n",
        "        pred_train, Trained_models = self.linear_fit(L3,L4,X_train,y_train,functions,models)\n",
        "        mse_train = self.rmse(y_train,pred_train)\n",
        "\n",
        "        if optimize_test_data:\n",
        "          L1,L2,L3,L4 = self.forwardPass(popParam[i],X_test,inputsTest,AntTest,L1Test,L2Test,functions)\n",
        "          pred_test = self.linear_predict(L3,L4,X_test,functions,Trained_models)\n",
        "          mse_test = self.rmse(y_test,pred_test)\n",
        "                    \n",
        "          PopulationError.append((mse_train+mse_test)/2)\n",
        "          bestModelLst.append(Trained_models)\n",
        "        else:\n",
        "          PopulationError.append(mse_train)\n",
        "          bestModelLst.append(Trained_models)\n",
        "\n",
        "      bestParamIndex = np.argmin(PopulationError)\n",
        "      bestParam = deepcopy(popParam[bestParamIndex])\n",
        "      bestModel = bestModelLst[bestParamIndex]\n",
        "      print(gen,\"RMSE is: \",PopulationError[bestParamIndex])   \n",
        "    return bestParam, bestModel\n",
        "\n",
        "  def predict(self,X,bestParam,bestModel):\n",
        "    functions = self.functions\n",
        "    inputs,Ant,L1,L2 = self.initialize(X)\n",
        "    L1,L2,L3,L4 = self.forwardPass(bestParam,X,inputs,Ant,L1,L2,functions)\n",
        "    pred = self.linear_predict(L3,L4,X,functions,bestModel)\n",
        "    return pred"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndentationError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-8-425c68977df1>\"\u001b[0;36m, line \u001b[0;32m133\u001b[0m\n\u001b[0;31m    def rmse(true, pred):\u001b[0m\n\u001b[0m                          ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected unindent\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vczXA0g8pIPx"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 622
        },
        "id": "Ni-O7SYDiTka",
        "outputId": "39a207bc-9349-4ef0-ea19-0f652111ad89"
      },
      "source": [
        "\n",
        "from sklearn.model_selection import train_test_split \n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "data = pd.read_excel('walkertrain.xlsx')\n",
        "test = pd.read_excel('walkertest.xlsx')\n",
        "\n",
        "Data = data.loc[:,['x','y','v']]\n",
        "test = test.loc[:,['x','y','v']]\n",
        "\n",
        "#Data = data.loc[:,['FC','VM','Ash','Moisture','Cal V']]\n",
        "\n",
        "# digitizing continuous variable\n",
        "aa = Data['v']\n",
        "minima = aa.min()\n",
        "maxima = aa.max()\n",
        "bins = np.linspace(minima-1,maxima+1, 3)\n",
        "binned = np.digitize(aa, bins)\n",
        "plt.hist(binned, bins=50)\n",
        "data_train, data_test = train_test_split(Data, test_size=0.2,\n",
        "                                          random_state=101,stratify=binned)\n",
        "\n",
        "X_train = data_train.drop(\"v\",axis=1).values\n",
        "y_train = data_train[\"v\"].copy().values\n",
        "X_test = data_test.drop(\"v\",axis=1).values\n",
        "y_test = data_test[\"v\"].copy().values\n",
        "X_val = test.drop(\"v\",axis=1).values\n",
        "y_val = test[\"v\"].copy().values\n",
        "\n",
        "scaler_x = MinMaxScaler()\n",
        "scaler_y = MinMaxScaler()\n",
        "scaler_x.fit(X_train)\n",
        "X_train = scaler_x.transform(X_train)\n",
        "X_test = scaler_x.transform(X_test)\n",
        "#X_val = scaler_x.transform(X_val)\n",
        "scaler_y.fit(y_train.reshape(-1,1))\n",
        "y_train = scaler_y.transform(y_train.reshape(-1,1))\n",
        "y_test = scaler_y.transform(y_test.reshape(-1,1))\n",
        "#y_val = scaler_y.transform(y_val.reshape(-1,1))\n",
        "\n",
        "\n",
        "from ANFIS import EVOLUTIONARY_ANFIS\n",
        "\n",
        "E_Anfis = EVOLUTIONARY_ANFIS(functions=3,generations=500,offsprings=10,\n",
        "                             mutationRate=0.2,learningRate=0.2,chance=0.7,ruleComb=\"simple\")\n",
        "\n",
        "bestParam, bestModel = E_Anfis.fit(X_train,y_train,optimize_test_data=False)\n",
        "\n",
        "bestParam, bestModel = E_Anfis.fit(X_train,y_train,X_test,y_test,optimize_test_data=True)\n",
        "\n",
        "from scipy.stats import pearsonr\n",
        "pred_train = E_Anfis.predict(X_train,bestParam,bestModel)\n",
        "pearsonr(y_train,pred_train.reshape(-1,1))\n",
        "\n",
        "pred_test = E_Anfis.predict(X_test,bestParam,bestModel)\n",
        "pearsonr(y_test,pred_test.reshape(-1,1))\n",
        "        "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-8d4428dac9e4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mANFIS\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mEVOLUTIONARY_ANFIS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m E_Anfis = EVOLUTIONARY_ANFIS(functions=3,generations=500,offsprings=10,\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'ANFIS'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j_CVul4IjTSF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}